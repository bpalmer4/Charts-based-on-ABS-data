{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAIRU Model\n",
    "\n",
    "Modelling the non-accelerating inflation rate of unemployment (NAIRU) for the Australian economy, using a variant of the RBA's approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The broad approach\n",
    "\n",
    "We are using a Baysian approach to solve a system of equations:\n",
    "\n",
    "* The NAIRU state-space equation:\n",
    "\n",
    "$$ U^{*}_{t} = U^{*}_{t-1} + \\epsilon_{N} $$\n",
    "\n",
    "* The price-inflation equation:\n",
    "\n",
    "$$ \\Delta\\rho_{t} = \\alpha_{pi}(\\Delta4\\rho^{m}_{t-1} - \\Delta4\\rho^{m}_{t-2}) + \\sum_{k=1}^{2}\\beta_{pi(k)}\\Delta\\rho_{t-k} + \n",
    "   \\gamma_{pi}\\frac{(U_t - U^*_t)}{U_t} + \\delta_{pi}\\Delta\\rho^{e}_{t} + \n",
    "   \\xi_{pi}\\Xi^2_{t-2} + \\epsilon_{pi}$$\n",
    "\n",
    "* The wage-growth equation:\n",
    "\n",
    "$$ \\Delta ulc_t = \\beta_{wg}\\sum_{k=1}^2\\Delta\\rho_{t-k} + \\gamma_{wg}\\frac{(U_t - U^*_t)}{U_t} + \n",
    "   \\delta_{wg}\\Delta\\rho^{e}_{t} + \\lambda_{wg}\\frac{(U_{t-1} - U_{t-2})}{U_t} + \\epsilon_{wg}$$\n",
    "\n",
    "Where:\n",
    "\n",
    " * $U^{*}$ is the NAIRU (expressed as a percentage of the labour force)\n",
    " * $U$ is the unemployment rate (expressed as a percentage of the labour force)\n",
    " * $\\Delta\\rho$ is the percentage change in the trimmed mean CPI from the previous quarter\n",
    " * $\\Delta4\\rho^{m}$ is the four quarter percentage change in the import price index\n",
    " * $\\Delta\\rho^{e}$ is the long-run quarterly inflation expectation\n",
    " * $\\Xi$ is the Global Supply Chain Price Index (proxy for COVID-19 effects)\n",
    " * $\\Delta ulc$ is the quarterly change in percentage terms for the unit labour costs\n",
    " * $\\epsilon$ is the error term in the various equations, which is normally distributed around zero\n",
    "\n",
    " Note:\n",
    " \n",
    "  * Only using two historical inflation terms (and not three) in the price inflation equation. The RBA uses three. This is because the beta3_pi term was not significantly different to zero.\n",
    "  * Similarly, the $\\lambda_{pi}\\frac{(U_{t-1} - U_{t-2})}{U_t}$ term was not used in the price inflation equation, as it did produce a statistically significant $\\lambda_{pi}$ parameter.\n",
    "  * The use of the global supply chain price index during the COVID-19 period (2020Q2 to 2023Q2) is an addition to the RBA (hat tip to Zac Gross for first exploring this approach)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acknowledgements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work has drawn on ideas and approaches in the following:\n",
    "\n",
    "Most useful:\n",
    "\n",
    " * https://www.rba.gov.au/publications/bulletin/2017/jun/pdf/bu-0617-2-estimating-the-nairu-and-the-unemployment-gap.pdf\n",
    "\n",
    " * https://treasury.gov.au/sites/default/files/2021-04/p2021-164397_estimatingthenairuinaustralia.pdf\n",
    "\n",
    " * https://github.com/MacroDave/NAIRU\n",
    "\n",
    " * https://gross.substack.com/p/navigating-the-nairu?utm_source=publication-search\n",
    "\n",
    "Also useful:\n",
    "\n",
    " * https://www.rba.gov.au/education/resources/explainers/pdf/nairu.pdf?v=2024-05-09-14-09-00\n",
    "\n",
    " * https://www.rbnz.govt.nz/-/media/project/sites/rbnz/files/publications/analytical-notes/2018/an2018-04.pdf\n",
    "\n",
    " * https://cmr.uni-koeln.de/fileadmin/wiso_fak/cmr/pdf/Berger_Publication_list/nairu.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:27:16.406793Z",
     "iopub.status.busy": "2025-09-03T22:27:16.406412Z",
     "iopub.status.idle": "2025-09-03T22:27:16.412665Z",
     "shell.execute_reply": "2025-09-03T22:27:16.412040Z"
    }
   },
   "outputs": [],
   "source": [
    "# system imports\n",
    "from typing import cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:27:16.415816Z",
     "iopub.status.busy": "2025-09-03T22:27:16.415531Z",
     "iopub.status.idle": "2025-09-03T22:27:19.025758Z",
     "shell.execute_reply": "2025-09-03T22:27:19.025430Z"
    }
   },
   "outputs": [],
   "source": [
    "# Analtic imports\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm  # type: ignore[import-untyped]\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from readabs import read_abs_series, read_rba_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:27:19.027124Z",
     "iopub.status.busy": "2025-09-03T22:27:19.026973Z",
     "iopub.status.idle": "2025-09-03T22:27:19.031597Z",
     "shell.execute_reply": "2025-09-03T22:27:19.031376Z"
    }
   },
   "outputs": [],
   "source": [
    "# local imports\n",
    "import mgplot as mg \n",
    "import henderson\n",
    "from abs_structured_capture import ReqsDict, ReqsTuple, get_abs_data, load_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:27:19.032553Z",
     "iopub.status.busy": "2025-09-03T22:27:19.032493Z",
     "iopub.status.idle": "2025-09-03T22:27:19.036153Z",
     "shell.execute_reply": "2025-09-03T22:27:19.035945Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting set-up\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "CHART_DIR = \"./CHARTS/NAIRU/\"\n",
    "mg.set_chart_dir(CHART_DIR)\n",
    "mg.clear_chart_dir()\n",
    "\n",
    "RFOOTER = \"ABS: 1364.0.15.003\"\n",
    "\n",
    "# display charts in this notebook\n",
    "SHOW = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data capture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:27:19.037093Z",
     "iopub.status.busy": "2025-09-03T22:27:19.037041Z",
     "iopub.status.idle": "2025-09-03T22:27:19.038498Z",
     "shell.execute_reply": "2025-09-03T22:27:19.038308Z"
    }
   },
   "outputs": [],
   "source": [
    "def monthly_to_quarterly(data: pd.Series) -> pd.Series:\n",
    "    \"\"\"Convert monthly data to quarterly data by taking the mean of\n",
    "    the three months in each quarter. Ignore quarters with less than\n",
    "    three months data. Drop NA items.\"\"\"\n",
    "\n",
    "    return (\n",
    "        data.groupby(pd.PeriodIndex(data.index, freq=\"Q\"))\n",
    "        .agg([\"mean\", \"count\"])\n",
    "        .apply(lambda x: x[\"mean\"] if x[\"count\"] == 3 else np.nan, axis=1)\n",
    "        .dropna()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:27:19.039400Z",
     "iopub.status.busy": "2025-09-03T22:27:19.039332Z",
     "iopub.status.idle": "2025-09-03T22:27:19.040903Z",
     "shell.execute_reply": "2025-09-03T22:27:19.040704Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot the 2.5% annual inflation target in quarterly terms\n",
    "\n",
    "QUARTERLY_TARGET = {\n",
    "    \"axhline\": {\n",
    "        \"y\": (pow(1.025, 0.25) - 1) * 100,\n",
    "        \"linestyle\": \"dashed\",\n",
    "        \"linewidth\": 0.75,\n",
    "        \"color\": \"darkred\",\n",
    "        \"label\": \"Quarterly growth consistent with 2.5% annual inflation\",\n",
    "    }\n",
    "}\n",
    "\n",
    "QUARTERLY_RANGE = {\n",
    "    \"axhspan\": {\n",
    "        \"ymin\": (pow(1.02, 0.25) - 1) * 100,\n",
    "        \"ymax\": (pow(1.03, 0.25) - 1) * 100,\n",
    "        \"color\": \"#ffdddd\",\n",
    "        \"label\": \"Quarterly growth consistent with 2-3% annual inflation target\",\n",
    "        \"zorder\": -1,\n",
    "    }\n",
    "}\n",
    "\n",
    "ANNUAL_RANGE = {\n",
    "    \"axhspan\": {\n",
    "        \"ymin\": 2,\n",
    "        \"ymax\": 3,\n",
    "        \"color\": \"#dddddd\",\n",
    "        \"label\": \"2-3% annual inflation target\",\n",
    "        \"zorder\": -1,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unemployment rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:27:19.041869Z",
     "iopub.status.busy": "2025-09-03T22:27:19.041800Z",
     "iopub.status.idle": "2025-09-03T22:27:28.336702Z",
     "shell.execute_reply": "2025-09-03T22:27:28.336392Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_unemployment() -> tuple[pd.Series, pd.Series, pd.Series]:\n",
    "    \"\"\"Get the unemployment related data from the ABS and\n",
    "    calculate the UE rate, and the change in the UE rate.\"\"\"\n",
    "\n",
    "    wanted: ReqsDict = {\n",
    "        # ReqsTupleL cat, table, did, stype, unit, seek_yr_growth, calc_growth, zip_file\n",
    "        \"Labor Force\": \n",
    "            ReqsTuple(\"1364.0.15.003\", \"1364015003\", \"Total labour force ;\", \"S\", \"\", False, False, \"\"),\n",
    "        \"Unemployed\":\n",
    "            ReqsTuple(\"1364.0.15.003\", \"1364015003\", \"Total unemployed ;\", \"S\", \"\", False, False, \"\"),\n",
    "    }\n",
    "    data = get_abs_data(wanted)\n",
    "    u = (data[\"Unemployed\"] / data[\"Labor Force\"]) * 100\n",
    "    n = 3\n",
    "    us = u.rolling(window=n, min_periods=n, center=True).mean()\n",
    "    u = us.where(us.notna(), other=u)\n",
    "\n",
    "    # calculate the change in the UE rate as a proportion of the UE rate\n",
    "    delta_u = u.diff(1)\n",
    "    delta_u_1 = delta_u.shift(1)\n",
    "\n",
    "    # Plot the data\n",
    "    common_format = {\n",
    "        \"lfooter\": \"Australia. Seasonally adjusted series. Quarterly data. \",\n",
    "        \"rfooter\": RFOOTER,\n",
    "        \"show\": SHOW,\n",
    "        \"y0\": True,\n",
    "    }\n",
    "\n",
    "    mg.line_plot_finalise(\n",
    "        u,\n",
    "        title=\"Unemployment rate\",\n",
    "        ylabel=\"Per cent of Labour Force\",\n",
    "        **common_format,\n",
    "    )\n",
    "\n",
    "    mg.line_plot_finalise(\n",
    "        delta_u,\n",
    "        title=\"Change in the unemployment rate (ΔU)\",\n",
    "        ylabel=\"Q/Q Percentage points\",\n",
    "        **common_format,\n",
    "    )\n",
    "\n",
    "    # return the values\n",
    "    return u, delta_u, delta_u_1\n",
    "\n",
    "\n",
    "U, ΔU, ΔU_1 = get_unemployment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:27:28.338004Z",
     "iopub.status.busy": "2025-09-03T22:27:28.337936Z",
     "iopub.status.idle": "2025-09-03T22:27:32.125339Z",
     "shell.execute_reply": "2025-09-03T22:27:32.125065Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_inflation(measure=\"TM\") -> tuple[pd.Series, pd.Series, pd.Series, pd.Series]:\n",
    "    \"\"\"Use HFCE IPD smoothed as a measure of core inflation.\n",
    "    Returns: A tuple of four series - the core inflation rate, and that\n",
    "    rate lagged by 1, 2 and 3 quarters.\"\"\"\n",
    "\n",
    "    # -- will need a rework when the CPI is updated in late January 2026 --\n",
    "    tm = \"Percentage Change from Previous Period ;  Trimmed Mean ;  Australia ;\"\n",
    "    headline = \"Percentage Change from Previous Period ;  All groups CPI, seasonally adjusted ;  Australia ;\"\n",
    "    old_cpi = \"./ABS-Data/Qrtly-CPI-Time-series-spreadsheets-all.zip\"\n",
    "    wanted = {\n",
    "    \"Trimmed Mean\" :\n",
    "        ReqsTuple(\"\", \"640106\", tm, \"S\", \"\", False, False, old_cpi),\n",
    "    }\n",
    "    data = get_abs_data(wanted)\n",
    "    n = 3  # must be odd - 1 indicates no smoothing, 3 and 5 are the other options for more smoothing\n",
    "    smooth_trim = data[\"Trimmed Mean\"].rolling(window=n, min_periods=n, center=True).mean()\n",
    "    inflation = smooth_trim.where(smooth_trim.notna(), other=data[\"Trimmed Mean\"])\n",
    "\n",
    "    mg.line_plot_finalise(\n",
    "        inflation,\n",
    "        title=\"Q/Q Inflation\",\n",
    "        ylabel=\"Q/Q Percentage change\",\n",
    "        lfooter=\"Australia. Seasonally adjusted series. Quarterly data. \",\n",
    "        rfooter=\"ABS\",\n",
    "        show=SHOW,\n",
    "        y0=True,\n",
    "        tag=\"qtr\",\n",
    "        legend=True,\n",
    "        axhspan=QUARTERLY_RANGE[\"axhspan\"],\n",
    "    )\n",
    "\n",
    "    delta_rho = inflation \n",
    "    delta_rho_1 = delta_rho.shift(periods=1).dropna()\n",
    "    delta_rho_2 = delta_rho.shift(periods=2).dropna()\n",
    "    delta_rho_3 = delta_rho.shift(periods=3).dropna()\n",
    "\n",
    "    return delta_rho, delta_rho_1, delta_rho_2, delta_rho_3\n",
    "\n",
    "\n",
    "Δρ, Δρ_1, Δρ_2, Δρ_3 = get_inflation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Long-run inflation expectations (synthetic data, based on RBA 10 year bonds)\n",
    "\n",
    "This is a very rough first approximation. Need to come back to this. The 2021 Treasury paper has some useful discussion on estimating inflation expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inflation_expectations() -> pd.Series:\n",
    "    history_df = pd.read_excel(\n",
    "        \"https://www.rba.gov.au/statistics/tables/xls-hist/f02histhist.xls\",\n",
    "        skiprows=10,\n",
    "        header=0,\n",
    "        index_col=0,\n",
    "    )\n",
    "    history_df.index = pd.PeriodIndex(history_df.index, freq=\"Q\")\n",
    "    history_s = history_df.groupby(history_df.index).mean()[\"FCMYGBAG10\"]\n",
    "\n",
    "    current, _meta = read_rba_table(\"F2.1\")\n",
    "    current_s = current[\"FCMYGBAG10\"]\n",
    "    current_s.index = pd.PeriodIndex(current_s.index, freq=\"Q\")\n",
    "    current_s = current_s.groupby(current_s.index).mean()\n",
    "\n",
    "    expt = pd.concat([history_s.dropna(), current_s.dropna()])\n",
    "    expt = expt[~expt.index.duplicated(keep='last')]\n",
    "    assert expt.index.is_monotonic_increasing\n",
    "    n = 5\n",
    "    smooth_expt = expt.rolling(window=n, min_periods=n, center=True).mean()\n",
    "    expt = smooth_expt.where(smooth_expt.notna(), other=expt)\n",
    "\n",
    "    full_range = pd.period_range(expt.index.min(), expt.index.max(), freq='Q')\n",
    "    missing = full_range.difference(expt.index)\n",
    "    if len(missing) > 0:\n",
    "        print(f\"Filling missing expected inflation data for quarters: {missing}\")\n",
    "        expt = expt.reindex(full_range).interpolate(method='linear')\n",
    "\n",
    "    delta_exp = expt.diff(1).dropna()\n",
    "    mg.line_plot_finalise(\n",
    "        delta_exp,\n",
    "        title=\"Q/Q Inflation Expectations\",\n",
    "        ylabel=\"Q/Q Percentage change\",\n",
    "        lfooter=\"Australia. Quarterly data. \",\n",
    "        rfooter=\"RBA\",\n",
    "        show=SHOW,\n",
    "        y0=True,\n",
    "        tag=\"qtr\",\n",
    "        legend=True,\n",
    "    )\n",
    "    return delta_exp.astype(float) / 4 # roughly convert to quarterly\n",
    "\n",
    "\n",
    "Δρe = get_inflation_expectations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import prices (from ABS 6457)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:27:32.219512Z",
     "iopub.status.busy": "2025-09-03T22:27:32.219442Z",
     "iopub.status.idle": "2025-09-03T22:27:34.381178Z",
     "shell.execute_reply": "2025-09-03T22:27:34.380944Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_import_pricing() -> tuple[pd.Series, pd.Series]:\n",
    "    \"\"\"Get the import pricing data from the ABS and calculate the\n",
    "    change in import prices as a proportion of the import prices.\"\"\"\n",
    "\n",
    "    # Import Price Index by Balance of Payments, index, original\n",
    "    trade, _trade_meta = read_abs_series(cat=\"6457.0\", series_id=\"A2298279F\")\n",
    "    log_import_prices = trade[\"A2298279F\"].apply(np.log)\n",
    "    delta4_log_import_prices = log_import_prices.diff(periods=4).dropna() * 100\n",
    "    dlip_1 = delta4_log_import_prices.shift(periods=1).dropna()\n",
    "    dlip_2 = delta4_log_import_prices.shift(periods=2).dropna()\n",
    "\n",
    "    # plot the data\n",
    "    ax = dlip_1.plot(lw=2)\n",
    "    mg.finalise_plot(\n",
    "        ax,\n",
    "        title=\"Lagged change in import prices (Δ4ρm_1)\",\n",
    "        ylabel=\"diff(log(Import Price Index))*100\",\n",
    "        y0=True,\n",
    "        lfooter=\"Australia. Quarterly data. \",\n",
    "        rfooter=\"ABS 6457\",\n",
    "        show=SHOW,\n",
    "    )\n",
    "\n",
    "    return dlip_1, dlip_2\n",
    "\n",
    "\n",
    "Δ4ρm_1, Δ4ρm_2 = get_import_pricing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit labour costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:27:34.382307Z",
     "iopub.status.busy": "2025-09-03T22:27:34.382245Z",
     "iopub.status.idle": "2025-09-03T22:27:39.146734Z",
     "shell.execute_reply": "2025-09-03T22:27:39.146452Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ulc() -> pd.Series:\n",
    "    \"\"\"Quarterly unit labour costs growth.\"\"\"\n",
    "\n",
    "    nat_accounts, _nat_accounts_meta = read_abs_series(\n",
    "        cat=\"5206.0\", series_id=[\"A2304402X\", \"A2302915V\"]\n",
    "    )\n",
    "    ulc = nat_accounts[\"A2302915V\"] / nat_accounts[\"A2304402X\"]\n",
    "    log_ulc = ulc.apply(np.log)\n",
    "    delta_ulc = (log_ulc.diff(periods=1)).dropna() * 100\n",
    "\n",
    "    # plot the data\n",
    "    term = 13\n",
    "    trend = henderson.hma(delta_ulc, term)\n",
    "    mg.line_plot_finalise(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"Qrtly unit labour costs growth\": delta_ulc,\n",
    "                f\"{term}-term Henderson moving average\": trend,\n",
    "            }\n",
    "        ),\n",
    "        title=\"Qrtly unit labour costs growth\",\n",
    "        ylabel=\"diff(log(ULC))*100\",\n",
    "        lfooter=\"Australia. Quarterly data. \",\n",
    "        rfooter=\"ABS 5206\",\n",
    "        width=[1.5, 2.5],\n",
    "        y0=True,\n",
    "        show=SHOW,\n",
    "    )\n",
    "    return delta_ulc\n",
    "\n",
    "\n",
    "Δulc = get_ulc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global supply constraints during the COVID-19 period\n",
    "\n",
    "This is an addition to the RBA model. The Global Supply Chain Price Index is used for a limited time period to approximate the related impacts of COVID-19 and the start of the Ukraine war on prices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:27:39.147964Z",
     "iopub.status.busy": "2025-09-03T22:27:39.147902Z",
     "iopub.status.idle": "2025-09-03T22:27:39.303728Z",
     "shell.execute_reply": "2025-09-03T22:27:39.303467Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_gscpi() -> tuple[pd.Series, pd.Series]:\n",
    "    \"\"\"Global Supply Chain Price Index. Usefulk for capturing global supply constraints\n",
    "    associated with the COVID-19 pandemic (and subsequent reopening and the Ukraine war).\n",
    "    From: https://www.newyorkfed.org/research/policy/gscpi#/interactive\"\"\"\n",
    "\n",
    "    gscpi = pd.read_excel(\n",
    "        \"./NAIRU_INPUTS/gscpi_data.xls\",\n",
    "        sheet_name=\"GSCPI Monthly Data\",\n",
    "        index_col=0,\n",
    "        parse_dates=True,\n",
    "    )[\"GSCPI\"]\n",
    "    gscpi = monthly_to_quarterly(gscpi)\n",
    "    gscpi.index = pd.PeriodIndex(gscpi.index, freq=\"Q\")\n",
    "    gscpi_1 = gscpi.shift(periods=1).dropna()\n",
    "    gscpi_2 = gscpi.shift(periods=2).dropna()\n",
    "    quarter = pd.Timestamp.today().to_period('Q')\n",
    "    dummy = pd.Series(1, pd.period_range(start=\"1959Q1\", end=quarter-1, freq=\"Q\"))\n",
    "    mask = (dummy.index >= \"2020Q1\") & (dummy.index <= \"2023Q2\")\n",
    "    dummy[mask] = 0  # - key dates for the COVID period\n",
    "    gscpi_1 = gscpi_1.where(dummy == 0, other=0).reindex(dummy.index).fillna(0)\n",
    "    gscpi_2 = gscpi_2.where(dummy == 0, other=0).reindex(dummy.index).fillna(0)\n",
    "\n",
    "    mg.line_plot_finalise(\n",
    "        gscpi,\n",
    "        title=\"Global supply constraints\",\n",
    "        ylabel=\"Index\",\n",
    "        lfooter=\"Quarterly data. \",\n",
    "        rfooter=\"Source: New York Fed\",\n",
    "        width=2,\n",
    "        y0=True,\n",
    "        show=SHOW,\n",
    "    )\n",
    "    mg.line_plot_finalise(\n",
    "        pd.DataFrame({\"gscpi_1\": gscpi_1, \"gscpi_2\": gscpi_2}),\n",
    "        title=\"Global supply constraints - lagged and constrained\",\n",
    "        ylabel=\"Index\",\n",
    "        lfooter=\"Quarterly data. \",\n",
    "        width=2,\n",
    "        show=SHOW,\n",
    "    )\n",
    "\n",
    "    return gscpi_1, gscpi_2\n",
    "\n",
    "\n",
    "ξ_1, ξ_2 = get_gscpi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data wrangling\n",
    "\n",
    "Make sure all the vectors are the same length, with no missing data, and in the correct vector format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:27:39.305021Z",
     "iopub.status.busy": "2025-09-03T22:27:39.304953Z",
     "iopub.status.idle": "2025-09-03T22:27:39.308617Z",
     "shell.execute_reply": "2025-09-03T22:27:39.308433Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_obs() -> tuple[dict[str, np.ndarray], pd.PeriodIndex]:\n",
    "    \"\"\"Here, we standardise the length of all observations\n",
    "    and place them into the obs dictionary, which is returned.\n",
    "    Beacuse the PeriodIndex data has been removed from the\n",
    "    \"observations matrix\", we also return the index separately.\"\"\"\n",
    "\n",
    "    observed = pd.DataFrame(\n",
    "        {\n",
    "            # Note: in the process of model development, not all of the data\n",
    "            # collected here will be used in the model. However, it is retained\n",
    "            # as it may be useful in the future.\n",
    "            # inflation\n",
    "            \"Δρ\": Δρ,  # core inflation\n",
    "            \"Δρ_1\": Δρ_1,  # lagged core inflation\n",
    "            \"Δρ_2\": Δρ_2,\n",
    "            \"Δρ_3\": Δρ_3,\n",
    "            \"Δρe\": Δρe,  # inflation expectations\n",
    "            # unemployment\n",
    "            \"U\": U,  # unemployment rate\n",
    "            \"ΔU\": ΔU,  # change in UE rate\n",
    "            \"ΔU_1\": ΔU_1,  # lagged change in UE rate\n",
    "            \"ΔU_1_over_U\": ΔU_1 / U,  # UE rate as a proportion of UE rate\n",
    "            # other\n",
    "            \"Δ4ρm_1\": Δ4ρm_1,  # annual change in import prices,\n",
    "            \"Δ4ρm_2\": Δ4ρm_2,  # annual change in import prices, lagged 1 period\n",
    "            \"Δulc\": Δulc,  # unit labour costs growth\n",
    "            \"ξ_1\": ξ_1,  # lagged supply shock\n",
    "            \"ξ_2\": ξ_2,  # lagged supply shock\n",
    "        }\n",
    "    )\n",
    "    print(observed.tail())\n",
    "    observed = observed.dropna(\n",
    "        how=\"any\"\n",
    "    )  # Note ulc comes from Nat Accounts, which is delayed data\n",
    "    print(\n",
    "        f\"Number of periods: {len(observed)}; from: \"\n",
    "        f\"{observed.index[0]}, concluding: {observed.index[-1]}\"\n",
    "    )\n",
    "\n",
    "    return {str(x): y.to_numpy() for x, y in observed.items()}, cast(\n",
    "        pd.PeriodIndex, observed.index\n",
    "    )\n",
    "\n",
    "\n",
    "obs, obs_index = build_obs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The PyMC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:27:39.309689Z",
     "iopub.status.busy": "2025-09-03T22:27:39.309629Z",
     "iopub.status.idle": "2025-09-03T22:27:39.335808Z",
     "shell.execute_reply": "2025-09-03T22:27:39.335523Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_model_coefficients(model: pm.Model, settings: dict, c: dict) -> dict:\n",
    "    \"\"\"Set model coefficients from a settings dictionary. Return those\n",
    "    coefficients in a dictionary.\n",
    "    Note: the coefficients are typically stochastic variables in the model,\n",
    "    using the normal distribution if mu is specified, or the half-normal.\"\"\"\n",
    "\n",
    "    coefficients = {}\n",
    "    with model:\n",
    "        for key in settings:\n",
    "            if key in c:\n",
    "                coefficients[key] = c[key]\n",
    "                continue\n",
    "            if \"mu\" in settings[key]:\n",
    "                coefficients[key] = pm.Normal(key, **settings[key])\n",
    "                continue\n",
    "            coefficients[key] = pm.HalfNormal(key, **settings[key])\n",
    "\n",
    "    return coefficients\n",
    "\n",
    "\n",
    "def price_inflation_equation(\n",
    "    inputs: dict[str, np.ndarray],\n",
    "    model: pm.Model,\n",
    "    nairu: pm.GaussianRandomWalk,\n",
    "    c: dict = {},  # any specified coefficient priors\n",
    ") -> None:\n",
    "    \"\"\"Inflation likelihood equation.\"\"\"\n",
    "\n",
    "    # Note: in the results section at the bottom of this notebook, it looks like\n",
    "    # beta3_pi and lambda_pi resolve to zero in the model. So I have removed them\n",
    "    # There is less than a 10% probability that alpha_pi is zero, which is not\n",
    "    # ideal, but it is not a major issue.\n",
    "\n",
    "    with model:\n",
    "        # priors - informed by previous successful runs of the model\n",
    "        settings = {\n",
    "            \"alpha_pi\": {\"mu\": 0.1, \"sigma\": 0.05},  # mport prices\n",
    "            \"beta1_pi\": {\"mu\": 0.3, \"sigma\": 0.1},  # lagged inflation\n",
    "            \"beta2_pi\": {\"mu\": 0.2, \"sigma\": 0.1},\n",
    "            # \"beta3_pi\": {\"mu\": 0.1, \"sigma\": 0.1},\n",
    "            \"gamma_pi\": {\"mu\": -0.4, \"sigma\": 0.2},  # unemployment gap\n",
    "            \"delta_pi\": {\"mu\": 0.4, \"sigma\": 0.2},  # inflation expectations\n",
    "            # \"lambda_pi\": {\"mu\": 0, \"sigma\": 5},       # UE rate change\n",
    "            \"epsilon_pi\": {\"sigma\": 0.2},  # error term\n",
    "            \"xi_2sq_pi\": {\"mu\": 0.1, \"sigma\": 1},  # COVID disruptions\n",
    "        }\n",
    "        mc = set_model_coefficients(model, settings, c)\n",
    "\n",
    "        # likelihood\n",
    "        _observed_price_inflation = pm.Normal(\n",
    "            \"observed_price_inflation\",\n",
    "            mu=mc[\"alpha_pi\"] * (inputs[\"Δ4ρm_1\"] - inputs[\"Δ4ρm_2\"])  # mport prices\n",
    "            + mc[\"beta1_pi\"] * inputs[\"Δρ_1\"]  # lagged inflation\n",
    "            + mc[\"beta2_pi\"] * inputs[\"Δρ_2\"]\n",
    "            # + mc[\"beta3_pi\"] * inputs[\"Δρ_3\"]\n",
    "            + mc[\"gamma_pi\"] * (inputs[\"U\"] - nairu) / inputs[\"U\"]  # unemployment gap\n",
    "            + mc[\"delta_pi\"] * inputs[\"Δρe\"]  # inflation expectations\n",
    "            # + mc[\"lambda_pi\"] * inputs[\"ΔU_1_over_U\"]  # UE rate change\n",
    "            + mc[\"xi_2sq_pi\"] * inputs[\"ξ_2\"] ** 2 * np.sign(inputs[\"ξ_2\"]),  # COVID\n",
    "            sigma=mc[\"epsilon_pi\"],\n",
    "            observed=inputs[\"Δρ\"],\n",
    "        )\n",
    "\n",
    "\n",
    "def wage_growth_equation(\n",
    "    inputs: dict[str, np.ndarray],\n",
    "    model: pm.Model,\n",
    "    nairu: pm.GaussianRandomWalk,\n",
    "    c: dict = {},  # any specified coefficient priors\n",
    ") -> None:\n",
    "    \"\"\"Wage growth likelihood equation.\"\"\"\n",
    "\n",
    "    with model:\n",
    "        # priors\n",
    "        settings = {\n",
    "            \"beta_wg\": {\"mu\": 0.3, \"sigma\": 0.1},  # lagged inflation\n",
    "            \"gamma_wg\": {\"mu\": -0.8, \"sigma\": 0.3},  # unemployment gap\n",
    "            \"delta_wg\": {\"mu\": 0.4, \"sigma\": 0.2},  # inflation expectations\n",
    "            \"lambda_wg\": {\"mu\": 0, \"sigma\": 5},  # UE rate change\n",
    "            \"epsilon_wg\": {\"sigma\": 1},  # error term\n",
    "        }\n",
    "        mc = set_model_coefficients(model, settings, c)\n",
    "\n",
    "        # likelihood\n",
    "        _observed_wage_growth = pm.Normal(\n",
    "            \"observed_wage_growth\",\n",
    "            mu=mc[\"beta_wg\"] * (inputs[\"Δρ_1\"] + inputs[\"Δρ_2\"])  # lagged inflation\n",
    "            + mc[\"gamma_wg\"] * ((inputs[\"U\"] - nairu) / inputs[\"U\"])  # unemployment gap\n",
    "            + mc[\"delta_wg\"] * inputs[\"Δρe\"]  # inflation expectations\n",
    "            + mc[\"lambda_wg\"] * inputs[\"ΔU_1_over_U\"],  # UE rate change\n",
    "            sigma=mc[\"epsilon_wg\"],\n",
    "            observed=inputs[\"Δulc\"],\n",
    "        )\n",
    "\n",
    "\n",
    "def nairu_equation(\n",
    "    inputs: dict[str, np.ndarray],\n",
    "    model: pm.Model,\n",
    "    c: dict = {},  # any specified coefficient priors\n",
    ") -> pm.GaussianRandomWalk:\n",
    "    \"\"\"Gaussian random walk for the NAIRU. This is a state space equation.\"\"\"\n",
    "\n",
    "    with model:\n",
    "        # use fixed/constrained innovation for quicker results\n",
    "        # the model typically resolves to a value of around 0.2 for the innovation\n",
    "        settings = {\n",
    "            \"nairu_innovation\": {\"mu\": 0.3, \"sigma\": 0.1},\n",
    "        }\n",
    "        mc = set_model_coefficients(model, settings, c)\n",
    "\n",
    "        nairu = (\n",
    "            pm.GaussianRandomWalk(\n",
    "                \"nairu\",\n",
    "                mu=0,  # no drift in this model\n",
    "                sigma=mc[\"nairu_innovation\"],\n",
    "                init_dist=pm.Normal.dist(mu=7.2, sigma=1.333),\n",
    "                steps=len(inputs[\"U\"]) - 1,\n",
    "            )\n",
    "            if \"nairu\" not in c\n",
    "            else c[\"nairu\"]\n",
    "        )\n",
    "\n",
    "    return nairu\n",
    "\n",
    "\n",
    "def define_model(inputs: dict[str, np.ndarray]) -> pm.Model:\n",
    "    \"\"\"Define the model for the NAIRU estimation.\"\"\"\n",
    "\n",
    "    model = pm.Model()\n",
    "\n",
    "    # nairu = nairu_equation(inputs, model)\n",
    "    ni = {\"nairu_innovation\": 0.25}  # use a constant rather than a stochastic prior\n",
    "    nairu = nairu_equation(inputs, model, c=ni)\n",
    "    price_inflation_equation(inputs, model, nairu)\n",
    "    wage_growth_equation(inputs, model, nairu)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "the_model = define_model(inputs=obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a map of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:27:39.336928Z",
     "iopub.status.busy": "2025-09-03T22:27:39.336868Z",
     "iopub.status.idle": "2025-09-03T22:27:39.338404Z",
     "shell.execute_reply": "2025-09-03T22:27:39.338195Z"
    }
   },
   "outputs": [],
   "source": [
    "### NOTE: broken under uv \n",
    "\n",
    "def produce_model_map(m: pm.Model, name: str = \"\") -> None:\n",
    "    \"\"\"Produce a map of the model.\"\"\"\n",
    "\n",
    "    gv = pm.model_to_graphviz(m)\n",
    "    gv.render(\n",
    "        format=\"png\",\n",
    "        filename=(f\"./NAIRU_INPUTS/nairu model{' ' if name else ''}{name}\"),\n",
    "    )\n",
    "    display(gv)\n",
    "\n",
    "\n",
    "# produce_model_map(the_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model to the data\n",
    "\n",
    "Note: sometimes the fitting starts with a stack of divergences. The best thing is to discard that run and re-run the model. \n",
    "\n",
    "This does not happen often, but it does suggest the model could be reparameterised a little."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:27:39.339315Z",
     "iopub.status.busy": "2025-09-03T22:27:39.339261Z",
     "iopub.status.idle": "2025-09-03T22:27:39.340694Z",
     "shell.execute_reply": "2025-09-03T22:27:39.340523Z"
    }
   },
   "outputs": [],
   "source": [
    "N_CORES: int = 6\n",
    "SAMPLES: int = 100_000\n",
    "SAMPLES_PER_CORE: int = int(SAMPLES / N_CORES)\n",
    "TUNE: int = 5_000  # per chain\n",
    "\n",
    "SAMPLE_ARGS = {\n",
    "    \"draws\": SAMPLES_PER_CORE,\n",
    "    \"tune\": TUNE,\n",
    "    \"cores\": N_CORES,\n",
    "    \"chains\": N_CORES,\n",
    "    \"nuts_sampler\": \"numpyro\",\n",
    "    # Arguments that might help avoid divergences (at the margins)\n",
    "    # {\"nuts\": {\"target_accept\": 0.95, \"max_treedepth\": 12}}}  # default 0.8, 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:27:39.341598Z",
     "iopub.status.busy": "2025-09-03T22:27:39.341534Z",
     "iopub.status.idle": "2025-09-03T22:27:39.342955Z",
     "shell.execute_reply": "2025-09-03T22:27:39.342787Z"
    }
   },
   "outputs": [],
   "source": [
    "# Note: if one or more chains complete very quickly relative to the others,\n",
    "#       then you will probably have sampling divergences, (check for\n",
    "#       divergences below) and you will need to run the fit again.\n",
    "#\n",
    "#       If one or more chains runs around half the speed of the others,\n",
    "#       then you may have a problem with chain convergence (see rhat below)\n",
    "#       and you will need to run the fit again.\n",
    "\n",
    "\n",
    "def fit_the_model(model: pm.Model, args: dict) -> az.InferenceData:\n",
    "    \"\"\"Fit the data to the model.\"\"\"\n",
    "\n",
    "    with model:\n",
    "        idata = pm.sample(\n",
    "            **args,\n",
    "            progressbar=True,\n",
    "            return_inferencedata=True,\n",
    "        )\n",
    "        az.plot_trace(idata)\n",
    "    return idata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:27:39.343761Z",
     "iopub.status.busy": "2025-09-03T22:27:39.343722Z",
     "iopub.status.idle": "2025-09-03T22:28:54.777050Z",
     "shell.execute_reply": "2025-09-03T22:28:54.776772Z"
    }
   },
   "outputs": [],
   "source": [
    "inference_data = fit_the_model(the_model, SAMPLE_ARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:28:54.779875Z",
     "iopub.status.busy": "2025-09-03T22:28:54.779780Z",
     "iopub.status.idle": "2025-09-03T22:29:00.369037Z",
     "shell.execute_reply": "2025-09-03T22:29:00.368762Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_inference_data(trace: az.InferenceData) -> None:\n",
    "    \"\"\"Check the inference data for potential problems.\"\"\"\n",
    "\n",
    "    def warn(w: bool) -> str:\n",
    "        return \"--- THERE BE DRAGONS ---> \" if w else \"\"\n",
    "\n",
    "    summary = az.summary(trace)\n",
    "\n",
    "    # check model convergence\n",
    "    max_r_hat = 1.01  # Best result is 1.0\n",
    "    statistic = summary.r_hat.max()\n",
    "    print(\n",
    "        f\"{warn(statistic > max_r_hat)}Maximum R-hat convergence diagnostic: {statistic}\"\n",
    "    )\n",
    "\n",
    "    # check effective sample size\n",
    "    min_ess = 400  # best if the minimum effective sample size is > 1000\n",
    "    statistic = summary[[\"ess_tail\", \"ess_bulk\"]].min().min()\n",
    "    print(\n",
    "        f\"{warn(statistic < min_ess)}Minimum effective sample size (ESS) estimate: {int(statistic)}\"\n",
    "    )\n",
    "\n",
    "    # check for divergences in the posterior sampling process\n",
    "    try:\n",
    "        diverging_count = int(np.sum(trace.sample_stats.diverging))  # type: ignore[attr-defined]\n",
    "    except (ValueError, AttributeError):  # No sample_stats, or no .diverging\n",
    "        diverging_count = 0\n",
    "    print(\n",
    "        f\"{warn(diverging_count > 0)}Divergent transitions in HMC sampling: {diverging_count}\"\n",
    "    )\n",
    "\n",
    "    # check the Baesian Fraction of Missing Information\n",
    "    min_bfmi = 0.3  # Values less than 0.3 indicate poor sampling\n",
    "    statistic = az.bfmi(trace).min()\n",
    "    print(\n",
    "        f\"{warn(statistic < min_bfmi)}Minimum Bayesian fraction of missing information: {statistic:0.2f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "check_inference_data(inference_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:29:00.370145Z",
     "iopub.status.busy": "2025-09-03T22:29:00.370068Z",
     "iopub.status.idle": "2025-09-03T22:29:00.371666Z",
     "shell.execute_reply": "2025-09-03T22:29:00.371431Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_var(var_name: str, trace: az.InferenceData) -> pd.DataFrame:\n",
    "    \"\"\"Extract the chains/draws for a specified var_name.\"\"\"\n",
    "\n",
    "    return (\n",
    "        az.extract(trace, var_names=var_name)\n",
    "        .transpose(\"sample\", ...)\n",
    "        .to_dataframe()[var_name]\n",
    "        .unstack(level=2)\n",
    "        .T\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:29:00.372625Z",
     "iopub.status.busy": "2025-09-03T22:29:00.372575Z",
     "iopub.status.idle": "2025-09-03T22:29:03.025866Z",
     "shell.execute_reply": "2025-09-03T22:29:03.025483Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_nairu(\n",
    "    trace: az.InferenceData,\n",
    "    unemployment: pd.Series,\n",
    "    input_index: pd.PeriodIndex,\n",
    ") -> None:\n",
    "    \"\"\"Plot the NAIRU.\"\"\"\n",
    "\n",
    "    nairu = get_var(\"nairu\", trace)\n",
    "    nairu.index = input_index.to_timestamp()\n",
    "    # cuts = [5, 15, 25, 35, 49]\n",
    "    cuts = [2.5, 16, 49.5]  # align lower two cuts to standard deviations\n",
    "    colors = [(p - min(cuts)) / (max(cuts) - min(cuts)) for p in cuts]\n",
    "    min_color_strength = 0.25\n",
    "    color_fracs = [c * (1.0 - min_color_strength) + min_color_strength for c in colors]\n",
    "    palette = \"Blues\"\n",
    "    _, ax = plt.subplots()\n",
    "    cmap = plt.get_cmap(palette)\n",
    "\n",
    "    for i, p in enumerate(cuts):\n",
    "        quants = p, 100 - p\n",
    "        label = f\"NAIRU {quants[1] - quants[0]:0.0f}% HDI\"\n",
    "        lower, upper = [nairu.quantile(q=q / 100.0, axis=1) for q in quants]\n",
    "        color = color_fracs[i]\n",
    "        ax.fill_between(\n",
    "            nairu.index,\n",
    "            upper,\n",
    "            lower,\n",
    "            color=cmap(color),\n",
    "            alpha=0.5,\n",
    "            label=label,\n",
    "            zorder=i + 1,\n",
    "        )\n",
    "    u = unemployment[unemployment.index >= input_index.min()]\n",
    "    ax.plot(u.index.to_timestamp(), u, label=\"_\", color=\"white\", lw=3, zorder=9)\n",
    "    ax.plot(\n",
    "        u.index.to_timestamp(),\n",
    "        u,\n",
    "        label=\"Unemployment rate\",\n",
    "        color=\"black\",\n",
    "        lw=1,\n",
    "        zorder=10,\n",
    "    )\n",
    "    latest = round(nairu.iloc[-1].quantile(0.5), 1)\n",
    "    ax.text(\n",
    "        nairu.index[-1],  # type: ignore[arg-type]\n",
    "        latest,\n",
    "        f\" {latest}\",\n",
    "        va=\"center\",\n",
    "        ha=\"left\",\n",
    "        color=\"black\",\n",
    "        fontsize=8,\n",
    "    )\n",
    "\n",
    "    # mark progressive changes to the NAIRU\n",
    "    # may need to adjust the x-axis labels.\n",
    "    ymin, _ymax = ax.get_ylim()\n",
    "    period = pd.Period(\"1985Q1\", freq=\"Q\")\n",
    "    while period < input_index[-1]:\n",
    "        index = period.to_timestamp()\n",
    "        progress = round(nairu.loc[index].quantile(0.5), 1)\n",
    "        ax.text(\n",
    "            index,  # type: ignore[arg-type]\n",
    "            ymin + 0.2,\n",
    "            f\"{progress}\",\n",
    "            va=\"bottom\",\n",
    "            ha=\"center\",\n",
    "            color=\"black\",\n",
    "            fontsize=8,\n",
    "        )\n",
    "        period += 20  # 5 years = 20 quarters\n",
    "\n",
    "    mg.finalise_plot(\n",
    "        ax,\n",
    "        title=\"Estimating the NAIRU\",\n",
    "        ylabel=\"Per cent\",\n",
    "        legend={\"loc\": \"upper right\", \"fontsize\": \"x-small\"},\n",
    "        lfooter=\"Australia. Non-Accelerating Inflation Rate of Unemployment.\",\n",
    "        show=SHOW,\n",
    "    )\n",
    "\n",
    "\n",
    "plot_nairu(inference_data, U, obs_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:29:03.027303Z",
     "iopub.status.busy": "2025-09-03T22:29:03.027219Z",
     "iopub.status.idle": "2025-09-03T22:29:04.445715Z",
     "shell.execute_reply": "2025-09-03T22:29:04.445440Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_parameter_summary(trace: az.InferenceData, model: pm.Model) -> None:\n",
    "    \"\"\"Print the summary results of the model,\n",
    "    useful for non-vector free variables in the model.\n",
    "    Also indicates where parameters may be indistinguisable from zero,\n",
    "    (ie. they are not significant within the model).\n",
    "\n",
    "    Note: It is critical that the gamma priors resolve to non-zero values,\n",
    "    as they indicate the NAIRU is significant within the model.\"\"\"\n",
    "\n",
    "    # Calculate median and Highest Debsity Intervals (HDI) for the model parameters\n",
    "    q = [0.02, 0.05, 0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.98]\n",
    "    print(f\"{(q[-1] - q[0]) * 100:0.0f}% HDI for the univariate model parameters:\")\n",
    "    results = {\n",
    "        str(name): (\n",
    "            az.extract(trace, var_names=str(name)).to_dataframe()[str(name)].quantile(q)\n",
    "        )\n",
    "        for name in model.free_RVs\n",
    "        # if str(name) not in [\"nairu\"]\n",
    "    }\n",
    "\n",
    "    # Identify if the HDI includes zero, which is often a sign of a\n",
    "    # problematic parameter in the regression-like equation.\n",
    "    # Other than the gamma values, paramaters should have at least a 90%\n",
    "    # proababikity of not being zero (2 or fewer starts -- see q above).\n",
    "    # For gamma, I want > 98% probability - i.e. there should be no stars.\n",
    "    # Note: this is a one-sided significane test.\n",
    "\n",
    "    df = pd.DataFrame(results).T.sort_index()\n",
    "    problem_intensity = (\n",
    "        # how many stars to give: 0,1=great, 2=okay, 3+=parameter not significant\n",
    "        pd.DataFrame(np.sign(df.T))  # type: ignore\n",
    "        .apply([lambda x: x.lt(0).sum(), lambda x: x.gt(0).sum()])\n",
    "        .min()\n",
    "        .astype(int)\n",
    "    )\n",
    "    marker = pd.Series([\"*\"] * len(problem_intensity), index=problem_intensity.index)\n",
    "    markers = (\n",
    "        marker.str.repeat(problem_intensity).reindex(problem_intensity.index).fillna(\"\")\n",
    "    )\n",
    "    df[\"Check Significance\"] = markers\n",
    "    display(df)\n",
    "\n",
    "\n",
    "print_parameter_summary(inference_data, the_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental short-run model\n",
    "\n",
    "Assume that the NAIRU is constant over (say) the past three years.\n",
    "\n",
    "Not convinced this is meaningful; takes substantial data to settle coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get short run data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:29:04.446895Z",
     "iopub.status.busy": "2025-09-03T22:29:04.446830Z",
     "iopub.status.idle": "2025-09-03T22:29:04.448751Z",
     "shell.execute_reply": "2025-09-03T22:29:04.448546Z"
    }
   },
   "outputs": [],
   "source": [
    "start = \"2021Q1\"\n",
    "data = pd.DataFrame(obs, index=obs_index).loc[lambda x: x.index >= start]\n",
    "short_run_obs = {str(x): y.to_numpy() for x, y in data.items()}\n",
    "short_run_obs_index = data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This short-run model (mostly reusing the model above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:29:04.449744Z",
     "iopub.status.busy": "2025-09-03T22:29:04.449691Z",
     "iopub.status.idle": "2025-09-03T22:29:04.460976Z",
     "shell.execute_reply": "2025-09-03T22:29:04.460727Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_model_constant(inputs: dict[str, np.ndarray]) -> pm.Model:\n",
    "    \"\"\"Define the model for the NAIRU estimation.\"\"\"\n",
    "\n",
    "    model = pm.Model()\n",
    "\n",
    "    # use a fixed single stochastic prior for the NAIRU\n",
    "    with model:\n",
    "        n = pm.Normal(\"nairu\", mu=5.1, sigma=2)\n",
    "    nairu = nairu_equation(inputs, model, c={\"nairu\": n, \"nairu_innovation\": None})\n",
    "\n",
    "    # use xi_2sq_pi from above ...\n",
    "    price_inflation_equation(inputs, model, nairu, c={\"xi_2sq_pi\": 0.042})\n",
    "    wage_growth_equation(inputs, model, nairu)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "constant_model = define_model_constant(inputs=short_run_obs)\n",
    "# produce_model_map(constant_model, name=\"recent-fixed-NAIRU\")  ### graphwiz prolem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model\n",
    "\n",
    "Note: increased target_accept to avoid divergences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:29:04.461942Z",
     "iopub.status.busy": "2025-09-03T22:29:04.461886Z",
     "iopub.status.idle": "2025-09-03T22:29:11.254798Z",
     "shell.execute_reply": "2025-09-03T22:29:11.254491Z"
    }
   },
   "outputs": [],
   "source": [
    "args = SAMPLE_ARGS | {\"nuts\": {\"target_accept\": 0.95}}\n",
    "inference_data_constant = fit_the_model(constant_model, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:29:11.256894Z",
     "iopub.status.busy": "2025-09-03T22:29:11.256827Z",
     "iopub.status.idle": "2025-09-03T22:29:11.614786Z",
     "shell.execute_reply": "2025-09-03T22:29:11.614505Z"
    }
   },
   "outputs": [],
   "source": [
    "check_inference_data(inference_data_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-03T22:29:11.615860Z",
     "iopub.status.busy": "2025-09-03T22:29:11.615795Z",
     "iopub.status.idle": "2025-09-03T22:29:11.670855Z",
     "shell.execute_reply": "2025-09-03T22:29:11.670589Z"
    }
   },
   "outputs": [],
   "source": [
    "print_parameter_summary(inference_data_constant, constant_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
