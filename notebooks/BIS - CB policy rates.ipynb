{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Central Bank Policy Rates - BIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system imports\n",
    "from pathlib import Path\n",
    "from urllib.error import HTTPError, URLError\n",
    "from typing import Any\n",
    "import textwrap as tw\n",
    "from collections.abc import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analytic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local imports\n",
    "from mgplot import (\n",
    "    set_chart_dir,\n",
    "    clear_chart_dir,\n",
    "    line_plot_finalise,\n",
    "    finalise_plot,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting set-up\n",
    "SOURCE = \"Source: BIS policy rates\"\n",
    "LFOOTER = \"Daily data.  Note: There are lags in BIS data reporting. \"\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "CHART_DIR = \"./CHARTS/BIS/\"\n",
    "set_chart_dir(CHART_DIR)\n",
    "clear_chart_dir()\n",
    "SHOW = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_code_to_name(country_code: str) -> str:\n",
    "    \"\"\"Convert 2-digit country codes to country names.\"\"\"\n",
    "\n",
    "    try:\n",
    "        country = pycountry.countries.get(alpha_2=country_code)\n",
    "        return country.name\n",
    "    except AttributeError:\n",
    "        if country_code == \"XM\":\n",
    "            return \"Euro Area\"\n",
    "        return country_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_missing_dates(data: pd.DataFrame | pd.Series) -> pd.DataFrame | pd.Series:\n",
    "    \"\"\"Reindex [and sort] a Series/DataFrame to include all missing dates in the index.\n",
    "    This function works for data with either a DatetimeIndex or PeriodIndex.\"\"\"\n",
    "\n",
    "    # check that the index is a DatetimeIndex or PeriodIndex\n",
    "    assert isinstance(data.index, pd.DatetimeIndex) or isinstance(\n",
    "        data.index, pd.PeriodIndex\n",
    "    )\n",
    "\n",
    "    function = (\n",
    "        pd.period_range if isinstance(data.index, pd.PeriodIndex) else pd.date_range\n",
    "    )\n",
    "    index = function(start=data.index.min(), end=data.index.max(), freq=\"D\")\n",
    "    data = data.reindex(index, fill_value=np.nan)\n",
    "    data = data.sort_index()\n",
    "    data = data.ffill()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache found (age: 0:07:08.992479)\n",
      "Using cached data (checked recently)\n",
      "Data shape: (2795, 39)\n",
      "Date range: 2018-01-01 to 2025-08-26\n",
      "period[D]\n"
     ]
    }
   ],
   "source": [
    "# takes a few minutes to run\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "def get_bis_data(start=\"2018-01-01\", end=None) -> tuple[pd.DataFrame, str]:\n",
    "    \"\"\"\n",
    "    Get central bank policy rates from the BIS for a select set of states.\n",
    "    Arguments: \n",
    "        start -- the start date for the data (default: 2018-01-01)\n",
    "        end -- the end date for the data (default: None, which means latest)\n",
    "    Returns a DataFrame of daily data and a string of the latest rates.\n",
    "    \"\"\"\n",
    "\n",
    "    states = sorted(\n",
    "        list(\n",
    "            set(\n",
    "                [  # ensure unique and sorted\n",
    "                    \"AU\",\n",
    "                    \"CA\",\n",
    "                    \"GB\",\n",
    "                    \"JP\",\n",
    "                    \"NO\",\n",
    "                    \"KR\",\n",
    "                    \"NZ\",\n",
    "                    \"SE\",\n",
    "                    \"US\",\n",
    "                    \"XM\",\n",
    "                    \"AR\",\n",
    "                    \"BR\",\n",
    "                    \"CL\",\n",
    "                    \"CN\",\n",
    "                    \"CZ\",\n",
    "                    \"DK\",\n",
    "                    \"HK\",\n",
    "                    \"HU\",\n",
    "                    \"IN\",\n",
    "                    \"ID\",\n",
    "                    \"IL\",\n",
    "                    \"MY\",\n",
    "                    \"MX\",\n",
    "                    \"PH\",\n",
    "                    \"PL\",\n",
    "                    \"RU\",\n",
    "                    \"ZA\",\n",
    "                    \"TH\",\n",
    "                    \"TR\",\n",
    "                    \"CO\",\n",
    "                    \"HR\",\n",
    "                    \"IS\",\n",
    "                    \"MA\",\n",
    "                    \"MK\",\n",
    "                    \"PE\",\n",
    "                    \"RO\",\n",
    "                    \"SA\",\n",
    "                    \"RS\",\n",
    "                    \"CH\",\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    box = {}\n",
    "    finals = []\n",
    "    for abbr in states:\n",
    "        for _trys in range(2):\n",
    "            state = country_code_to_name(abbr)\n",
    "            url = f\"https://stats.bis.org/api/v2/data/dataflow/BIS/WS_CBPOL/1.0/D.{abbr}?startPeriod={start}\"\n",
    "            if end:\n",
    "                url += f\"&endPeriod={end}\"\n",
    "            url += \"&format=csv\"\n",
    "            try:\n",
    "                df = pd.read_csv(url)[[\"TIME_PERIOD\", \"OBS_VALUE\"]]\n",
    "            except (HTTPError, URLError) as e:\n",
    "                print(f\"Internet Error: {state} {e}\")\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                # Empty dataset returns error\n",
    "                continue\n",
    "            if df.empty:\n",
    "                continue\n",
    "            s = pd.Series(\n",
    "                df[\"OBS_VALUE\"].values,\n",
    "                name=state,\n",
    "                dtype=float,\n",
    "                index=pd.to_datetime(df[\"TIME_PERIOD\"]),\n",
    "            )\n",
    "            if s.empty or s.isnull().all():\n",
    "                print(f\"Empty: {state}\")\n",
    "                continue\n",
    "            s = index_missing_dates(s)  # type: ignore[assignment]\n",
    "            box[state] = s\n",
    "            finals.append(f\"{abbr}: {s.iloc[-1]:.2f}\")\n",
    "            break\n",
    "\n",
    "    if not box:\n",
    "        return pd.DataFrame(), \"\"\n",
    "    \n",
    "    data = pd.DataFrame(box)\n",
    "    data.index = pd.PeriodIndex(data.index, freq=\"D\")\n",
    "\n",
    "    return data, \", \".join(finals)\n",
    "\n",
    "# Smart caching: update existing cache with recent data\n",
    "cache_file = Path(\"./bis_data_cache.pkl\")\n",
    "cache_age_limit = timedelta(hours=24)  # Check for updates every 24 hours\n",
    "\n",
    "try:\n",
    "    if cache_file.exists():\n",
    "        cache_time = datetime.fromtimestamp(cache_file.stat().st_mtime)\n",
    "        print(f\"Cache found (age: {datetime.now() - cache_time})\")\n",
    "        \n",
    "        # Load existing cache\n",
    "        with open(cache_file, 'rb') as f:\n",
    "            df_cached, _ = pickle.load(f)\n",
    "        \n",
    "        if datetime.now() - cache_time < cache_age_limit:\n",
    "            print(\"Using cached data (checked recently)\")\n",
    "            df = df_cached\n",
    "        else:\n",
    "            print(\"Updating cache with recent data...\")\n",
    "            # Get the last date in cache\n",
    "            last_cached_date = pd.to_datetime(df_cached.index[-1].strftime('%Y-%m-%d'))\n",
    "            \n",
    "            # Fetch data from 3 months before last cached date to ensure we capture any revisions\n",
    "            update_from = (last_cached_date - relativedelta(months=3)).strftime('%Y-%m-%d')\n",
    "            print(f\"Fetching data from {update_from} onwards (3 months overlap)...\")\n",
    "            df_update, _ = get_bis_data(start=update_from)\n",
    "            \n",
    "            if not df_update.empty:\n",
    "                # Combine cached and new data (new data takes precedence for overlapping dates)\n",
    "                df = df_cached.combine_first(df_update)\n",
    "                # Ensure all columns from both dataframes are present\n",
    "                for col in df_update.columns:\n",
    "                    if col not in df.columns:\n",
    "                        df[col] = df_update[col]\n",
    "                # Update overlapping data with fresh values (in case of revisions)\n",
    "                for col in df_cached.columns:\n",
    "                    if col in df_update.columns:\n",
    "                        df.loc[df_update.index, col] = df_update[col]\n",
    "                df = df.sort_index()\n",
    "                print(\"Cache updated with recent data\")\n",
    "            else:\n",
    "                print(\"No new data available, using existing cache\")\n",
    "                df = df_cached\n",
    "            \n",
    "            # Save updated cache\n",
    "            latest_rates = \", \".join([f\"{col[:2]}: {df[col].iloc[-1]:.2f}\" for col in df.columns if not pd.isna(df[col].iloc[-1])])\n",
    "            with open(cache_file, 'wb') as f:\n",
    "                pickle.dump((df, latest_rates), f)\n",
    "    else:\n",
    "        print(\"No cache found, fetching full dataset from BIS...\")\n",
    "        df, latest_rates = get_bis_data()  # takes around 3 minutes for full dataset\n",
    "        if not df.empty:\n",
    "            with open(cache_file, 'wb') as f:\n",
    "                pickle.dump((df, latest_rates), f)\n",
    "            print(\"Full dataset fetched and cached\")\n",
    "        else:\n",
    "            raise ValueError(\"Failed to fetch any data from BIS\")\n",
    "            \n",
    "    # Generate latest_rates string from the data\n",
    "    latest_rates = \", \".join([f\"{col[:2]}: {df[col].iloc[-1]:.2f}\" for col in df.columns if not pd.isna(df[col].iloc[-1])])\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error with data fetching: {e}\")\n",
    "    # Try to use stale cache if available\n",
    "    if cache_file.exists():\n",
    "        print(\"Using stale cache due to error...\")\n",
    "        with open(cache_file, 'rb') as f:\n",
    "            df, latest_rates = pickle.load(f)\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Date range: {df.index[0]} to {df.index[-1]}\")\n",
    "print(df.index.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By hand adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make adjustments when BIS data is lagged\n",
    "\n",
    "\n",
    "adjustments = {\n",
    "    # Nation : [adjustment, date-as-period]\n",
    "    \"Australia\": [3.6, pd.Period(\"2025-08-13\", freq=\"D\")],\n",
    "    \"New Zealand\": [3.0, pd.Period(\"2025-08-20\", freq=\"D\")],\n",
    "}\n",
    "\n",
    "\n",
    "def make_adjustments(frame: pd.DataFrame, adjust_dict: dict) -> pd.DataFrame:\n",
    "    \"\"\"Because the BIS data is highly lagged, we may need to adjust it for late\n",
    "    policy rate changes.\n",
    "    Arguments: frame -- the DataFrame to adjust\n",
    "               adjust_dict -- a dictionary of adjustments\n",
    "    Returns the adjusted DataFrame.\"\"\"\n",
    "\n",
    "    fail_if_too_long_ago = 21  # Days\n",
    "\n",
    "    for state, (adj, date) in adjust_dict.items():\n",
    "        if date > frame.index[-1]:\n",
    "            frame.loc[date, state] = adj\n",
    "            frame = index_missing_dates(frame)  # type: ignore[assignment]\n",
    "        else:\n",
    "            how_far_back = (date - frame.index[-1]) / np.timedelta64(1, \"D\")\n",
    "            if how_far_back > fail_if_too_long_ago:\n",
    "                print(f\"Failed to adjust {state} by {adj} on {date}\")\n",
    "                continue\n",
    "            frame.loc[date, state] = adj\n",
    "            frame.loc[frame.index > date, state] = np.nan\n",
    "            frame[state] = frame[state].ffill()\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "df = make_adjustments(df, adjustments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTER = 0\n",
    "\n",
    "\n",
    "def plot_rates(dataset: pd.DataFrame, start=\"2018-01-01\") -> None:\n",
    "    \"\"\"Plot the central bank policy rates.\"\"\"\n",
    "\n",
    "    widths = [1.5] * 40\n",
    "    if \"Australia\" in dataset.columns:\n",
    "        widths[dataset.columns.get_loc(\"Australia\")] = 3  # type: ignore[index]\n",
    "\n",
    "    if len(dataset.columns) < 10:\n",
    "        fs = 10\n",
    "    elif len(dataset.columns) < 20:\n",
    "        fs = 8\n",
    "    else:\n",
    "        fs = 6\n",
    "\n",
    "    global COUNTER\n",
    "    line_plot_finalise(\n",
    "        dataset[lambda x: x.index >= start],\n",
    "        title=\"Central Bank Policy Rates\",\n",
    "        ylabel=\"Annual Policy Rate (%)\",\n",
    "        rfooter=SOURCE,\n",
    "        lfooter=LFOOTER,\n",
    "        width=widths,\n",
    "        style=[\"-\", \"--\", \":\", \"-.\"] * 10,\n",
    "        legend={\"ncols\": 3, \"loc\": \"upper left\", \"fontsize\": fs},\n",
    "        y0=True,\n",
    "        zero_y=True,\n",
    "        tag=f\"{COUNTER}\",\n",
    "        show=SHOW,\n",
    "    )\n",
    "    COUNTER += 1\n",
    "\n",
    "\n",
    "comparable = [\n",
    "    \"Australia\",\n",
    "    \"Canada\",\n",
    "    \"Euro Area\",\n",
    "    \"New Zealand\",\n",
    "    \"United Kingdom\",\n",
    "    \"United States\",\n",
    "]\n",
    "bigly = [\n",
    "    \"United States\",\n",
    "    \"China\",\n",
    "    \"India\",\n",
    "    \"Euro Area\",\n",
    "    \"United Kingdom\",\n",
    "    \"Japan\",\n",
    "    \"Canada\",\n",
    "]\n",
    "ugly = [\"Argentina\", \"Russian Federation\", \"Türkiye\"]\n",
    "plot_rates(df[comparable])\n",
    "plot_rates(df[bigly])\n",
    "plot_rates(df[sorted([x for x in df.columns if x not in ugly])])\n",
    "plot_rates(df[ugly])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryanpalmer/ABS/.venv/lib/python3.13/site-packages/mgplot/finalise_plot.py:374: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n",
      "  fig.tight_layout(pad=TIGHT_LAYOUT_PAD)\n"
     ]
    }
   ],
   "source": [
    "MEAN_MEDIAN = 0.80  # proportion of non-na data points to plot mean and median\n",
    "\n",
    "\n",
    "def plot_world(\n",
    "    data: pd.DataFrame,\n",
    "    exclusions: Iterable = tuple(),\n",
    "    **kwargs: Any,\n",
    ") -> None:\n",
    "    \"\"\"Plot Australia vs the BIS monitored mean and median.\"\"\"\n",
    "\n",
    "    # Exclude problematic BIS states\n",
    "    keep = [x for x in data.columns if x not in exclusions]\n",
    "    my_data = data[keep].copy()\n",
    "\n",
    "    # plot remaining BIS states without legend label using the _ trick\n",
    "    mapper = {x: f\"_{x}\" for x in my_data.columns}\n",
    "    my_data = my_data.rename(columns=mapper)\n",
    "    ax = my_data.plot(color=\"blue\", lw=0.25, alpha=0.5)\n",
    "    back = {y: x for x, y in mapper.items()}\n",
    "    my_data = my_data.rename(columns=back)\n",
    "    my_data[\"Australia\"].dropna().plot(\n",
    "        ax=ax, color=\"darkorange\", lw=3, label=\"Australia\"\n",
    "    )\n",
    "\n",
    "    # plot mean if THRESHOLD proportion of non-na data points met\n",
    "    mean = my_data.mean(axis=1).where(\n",
    "        my_data.notna().sum(axis=1) >= len(my_data.columns) * MEAN_MEDIAN,\n",
    "        other=np.nan,\n",
    "    )\n",
    "    median = my_data.median(axis=1).where(\n",
    "        my_data.notna().sum(axis=1) >= len(my_data.columns) * MEAN_MEDIAN,\n",
    "        other=np.nan,\n",
    "    )\n",
    "    mean.plot(ax=ax, color=\"darkblue\", ls=\"--\", lw=2, label=\"BIS monitored mean\")\n",
    "    median.plot(ax=ax, color=\"darkred\", ls=\":\", lw=2, label=\"BIS monitored median\")\n",
    "\n",
    "    # plot\n",
    "    global PW_COUNTER  # yes, this is ugly\n",
    "    PW_COUNTER = PW_COUNTER + 1\n",
    "    finalise_plot(\n",
    "        ax,\n",
    "        xlabel=None,\n",
    "        y0=True,\n",
    "        rfooter=SOURCE,\n",
    "        tag=str(PW_COUNTER),\n",
    "        legend={\"loc\": \"best\", \"fontsize\": \"xx-small\"},\n",
    "        **kwargs,\n",
    "        show=SHOW,\n",
    "    )\n",
    "\n",
    "\n",
    "PW_COUNTER = 0\n",
    "plot_world(\n",
    "    df,\n",
    "    exclusions=ugly,\n",
    "    title=\"CB Policy Rates: Australia in World Context\",\n",
    "    ylabel=\"Annual Policy Rate (%)\",\n",
    "    lfooter=LFOOTER + f\" Excluded: {', '.join(ugly)}.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2025-09-04 08:48:13\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.13.6\n",
      "IPython version      : 9.4.0\n",
      "\n",
      "conda environment: n/a\n",
      "\n",
      "Compiler    : Clang 20.1.4 \n",
      "OS          : Darwin\n",
      "Release     : 24.6.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 14\n",
      "Architecture: 64bit\n",
      "\n",
      "pycountry : 24.6.1\n",
      "pathlib   : 1.0.1\n",
      "numpy     : 2.3.2\n",
      "mgplot    : 0.2.12\n",
      "dateutil  : 2.9.0.post0\n",
      "matplotlib: 3.10.5\n",
      "pandas    : 2.3.1\n",
      "typing    : 3.10.0.0\n",
      "\n",
      "Watermark: 2.5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -u -t -d --iversions --watermark --machine --python --conda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ABS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
